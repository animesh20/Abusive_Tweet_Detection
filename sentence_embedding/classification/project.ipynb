{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data and dividing into train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels\n",
    "labels = []\n",
    "with open('labels.txt') as f:\n",
    "    for line in f:\n",
    "        labels.append(int(line.strip()))\n",
    "y = np.array(labels)\n",
    "\n",
    "#load embeddings\n",
    "X = np.load('embeddings.npy')\n",
    "\n",
    "#dividing into training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "#for performance metric\n",
    "#racism:0, sexism:1, none:2\n",
    "target_names = ['racism', 'sexism', 'none']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.75      0.70      0.73       179\n",
      "     sexism       0.85      0.50      0.63       329\n",
      "       none       0.82      0.93      0.87      1077\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.76      0.73      0.75       179\n",
      "     sexism       0.87      0.52      0.65       329\n",
      "       none       0.83      0.94      0.88      1077\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.76      0.77      0.76       179\n",
      "     sexism       0.85      0.57      0.68       329\n",
      "       none       0.85      0.93      0.89      1077\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=4, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.78      0.75      0.77       179\n",
      "     sexism       0.86      0.56      0.68       329\n",
      "       none       0.84      0.94      0.89      1077\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=8, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.64      0.82      0.72       179\n",
      "     sexism       0.51      0.69      0.58       329\n",
      "       none       0.85      0.72      0.78      1077\n",
      "\n",
      "avg / total       0.76      0.72      0.73      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.180728\ttest-merror:0.18612\n",
      "[1]\ttrain-merror:0.178484\ttest-merror:0.183596\n",
      "[2]\ttrain-merror:0.174627\ttest-merror:0.184858\n",
      "[3]\ttrain-merror:0.175328\ttest-merror:0.187382\n",
      "[4]\ttrain-merror:0.174346\ttest-merror:0.188644\n",
      "[5]\ttrain-merror:0.173855\ttest-merror:0.188013\n",
      "[6]\ttrain-merror:0.173995\ttest-merror:0.188013\n",
      "[7]\ttrain-merror:0.173995\ttest-merror:0.187382\n",
      "[8]\ttrain-merror:0.172873\ttest-merror:0.189274\n",
      "[9]\ttrain-merror:0.172382\ttest-merror:0.186751\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.75      0.73      0.74       179\n",
      "     sexism       0.87      0.44      0.59       329\n",
      "       none       0.81      0.94      0.87      1077\n",
      "\n",
      "avg / total       0.82      0.81      0.80      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 4\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.09608\ttest-merror:0.192429\n",
      "[1]\ttrain-merror:0.088576\ttest-merror:0.185489\n",
      "[2]\ttrain-merror:0.083456\ttest-merror:0.184858\n",
      "[3]\ttrain-merror:0.080721\ttest-merror:0.181073\n",
      "[4]\ttrain-merror:0.078196\ttest-merror:0.17224\n",
      "[5]\ttrain-merror:0.075812\ttest-merror:0.172871\n",
      "[6]\ttrain-merror:0.073568\ttest-merror:0.169716\n",
      "[7]\ttrain-merror:0.070412\ttest-merror:0.170978\n",
      "[8]\ttrain-merror:0.068027\ttest-merror:0.171609\n",
      "[9]\ttrain-merror:0.066414\ttest-merror:0.171609\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.76      0.74      0.75       179\n",
      "     sexism       0.86      0.52      0.65       329\n",
      "       none       0.83      0.94      0.88      1077\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 8\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.071183\ttest-merror:0.195584\n",
      "[1]\ttrain-merror:0.06396\ttest-merror:0.180442\n",
      "[2]\ttrain-merror:0.059682\ttest-merror:0.18612\n",
      "[3]\ttrain-merror:0.057648\ttest-merror:0.184227\n",
      "[4]\ttrain-merror:0.056035\ttest-merror:0.181703\n",
      "[5]\ttrain-merror:0.052248\ttest-merror:0.17224\n",
      "[6]\ttrain-merror:0.050424\ttest-merror:0.171609\n",
      "[7]\ttrain-merror:0.047759\ttest-merror:0.171609\n",
      "[8]\ttrain-merror:0.045866\ttest-merror:0.17224\n",
      "[9]\ttrain-merror:0.04278\ttest-merror:0.169716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.76      0.74      0.75       179\n",
      "     sexism       0.84      0.54      0.66       329\n",
      "       none       0.84      0.93      0.88      1077\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 10\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.041377\ttest-merror:0.19306\n",
      "[1]\ttrain-merror:0.034224\ttest-merror:0.182334\n",
      "[2]\ttrain-merror:0.030016\ttest-merror:0.185489\n",
      "[3]\ttrain-merror:0.027281\ttest-merror:0.184227\n",
      "[4]\ttrain-merror:0.024125\ttest-merror:0.182334\n",
      "[5]\ttrain-merror:0.022021\ttest-merror:0.179811\n",
      "[6]\ttrain-merror:0.020128\ttest-merror:0.176656\n",
      "[7]\ttrain-merror:0.017603\ttest-merror:0.184227\n",
      "[8]\ttrain-merror:0.015218\ttest-merror:0.17918\n",
      "[9]\ttrain-merror:0.012483\ttest-merror:0.179811\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.73      0.73      0.73       179\n",
      "     sexism       0.83      0.52      0.64       329\n",
      "       none       0.83      0.93      0.88      1077\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 16\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.180728\ttest-merror:0.18612\n",
      "[1]\ttrain-merror:0.174837\ttest-merror:0.184858\n",
      "[2]\ttrain-merror:0.172312\ttest-merror:0.186751\n",
      "[3]\ttrain-merror:0.167613\ttest-merror:0.182965\n",
      "[4]\ttrain-merror:0.162985\ttest-merror:0.182334\n",
      "[5]\ttrain-merror:0.158637\ttest-merror:0.175394\n",
      "[6]\ttrain-merror:0.15492\ttest-merror:0.17224\n",
      "[7]\ttrain-merror:0.151343\ttest-merror:0.171609\n",
      "[8]\ttrain-merror:0.146925\ttest-merror:0.170347\n",
      "[9]\ttrain-merror:0.142787\ttest-merror:0.169716\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.74      0.74      0.74       179\n",
      "     sexism       0.88      0.54      0.67       329\n",
      "       none       0.84      0.93      0.88      1077\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.4\n",
    "param['max_depth'] = 4\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.09608\ttest-merror:0.192429\n",
      "[1]\ttrain-merror:0.081212\ttest-merror:0.182334\n",
      "[2]\ttrain-merror:0.06929\ttest-merror:0.177918\n",
      "[3]\ttrain-merror:0.060243\ttest-merror:0.177287\n",
      "[4]\ttrain-merror:0.052809\ttest-merror:0.176656\n",
      "[5]\ttrain-merror:0.044463\ttest-merror:0.165931\n",
      "[6]\ttrain-merror:0.03745\ttest-merror:0.173502\n",
      "[7]\ttrain-merror:0.030227\ttest-merror:0.168454\n",
      "[8]\ttrain-merror:0.025247\ttest-merror:0.169716\n",
      "[9]\ttrain-merror:0.019356\ttest-merror:0.167823\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.78      0.74      0.76       179\n",
      "     sexism       0.85      0.53      0.66       329\n",
      "       none       0.84      0.94      0.88      1077\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.4\n",
    "param['max_depth'] = 8\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.071183\ttest-merror:0.195584\n",
      "[1]\ttrain-merror:0.057578\ttest-merror:0.194953\n",
      "[2]\ttrain-merror:0.046777\ttest-merror:0.187382\n",
      "[3]\ttrain-merror:0.03738\ttest-merror:0.180442\n",
      "[4]\ttrain-merror:0.028263\ttest-merror:0.182334\n",
      "[5]\ttrain-merror:0.019917\ttest-merror:0.181703\n",
      "[6]\ttrain-merror:0.013886\ttest-merror:0.183596\n",
      "[7]\ttrain-merror:0.008977\ttest-merror:0.182334\n",
      "[8]\ttrain-merror:0.00512\ttest-merror:0.179811\n",
      "[9]\ttrain-merror:0.003507\ttest-merror:0.179811\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.75      0.70      0.72       179\n",
      "     sexism       0.83      0.53      0.64       329\n",
      "       none       0.83      0.93      0.88      1077\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.4\n",
    "param['max_depth'] = 10\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.180728\ttest-merror:0.18612\n",
      "[1]\ttrain-merror:0.169577\ttest-merror:0.181703\n",
      "[2]\ttrain-merror:0.16046\ttest-merror:0.176656\n",
      "[3]\ttrain-merror:0.154499\ttest-merror:0.176025\n",
      "[4]\ttrain-merror:0.147907\ttest-merror:0.17224\n",
      "[5]\ttrain-merror:0.139351\ttest-merror:0.168454\n",
      "[6]\ttrain-merror:0.130935\ttest-merror:0.169085\n",
      "[7]\ttrain-merror:0.124272\ttest-merror:0.170347\n",
      "[8]\ttrain-merror:0.117189\ttest-merror:0.167823\n",
      "[9]\ttrain-merror:0.111719\ttest-merror:0.164669\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.76      0.73      0.74       179\n",
      "     sexism       0.85      0.58      0.69       329\n",
      "       none       0.84      0.93      0.89      1077\n",
      "\n",
      "avg / total       0.84      0.84      0.83      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.8\n",
    "param['max_depth'] = 4\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.09608\ttest-merror:0.192429\n",
      "[1]\ttrain-merror:0.071323\ttest-merror:0.185489\n",
      "[2]\ttrain-merror:0.050144\ttest-merror:0.18612\n",
      "[3]\ttrain-merror:0.032892\ttest-merror:0.180442\n",
      "[4]\ttrain-merror:0.020478\ttest-merror:0.177287\n",
      "[5]\ttrain-merror:0.014096\ttest-merror:0.177918\n",
      "[6]\ttrain-merror:0.008205\ttest-merror:0.171609\n",
      "[7]\ttrain-merror:0.00561\ttest-merror:0.172871\n",
      "[8]\ttrain-merror:0.003577\ttest-merror:0.173502\n",
      "[9]\ttrain-merror:0.003156\ttest-merror:0.176025\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.74      0.73      0.74       179\n",
      "     sexism       0.82      0.56      0.67       329\n",
      "       none       0.84      0.92      0.88      1077\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.8\n",
    "param['max_depth'] = 8\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.180728\ttest-merror:0.18612\n",
      "[1]\ttrain-merror:0.168385\ttest-merror:0.177918\n",
      "[2]\ttrain-merror:0.159128\ttest-merror:0.174763\n",
      "[3]\ttrain-merror:0.150642\ttest-merror:0.177918\n",
      "[4]\ttrain-merror:0.142787\ttest-merror:0.17918\n",
      "[5]\ttrain-merror:0.132408\ttest-merror:0.181703\n",
      "[6]\ttrain-merror:0.126797\ttest-merror:0.177918\n",
      "[7]\ttrain-merror:0.119013\ttest-merror:0.173502\n",
      "[8]\ttrain-merror:0.109334\ttest-merror:0.175394\n",
      "[9]\ttrain-merror:0.101059\ttest-merror:0.174763\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.77      0.75      0.76       179\n",
      "     sexism       0.79      0.56      0.66       329\n",
      "       none       0.84      0.92      0.88      1077\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 1.0\n",
    "param['max_depth'] = 4\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
