{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data and dividing into train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15844, 300)\n"
     ]
    }
   ],
   "source": [
    "# Load labels\n",
    "labels = []\n",
    "with open('labels.txt') as f:\n",
    "    for line in f:\n",
    "        labels.append(int(line.strip()))\n",
    "y = np.array(labels)\n",
    "\n",
    "#load embeddings\n",
    "X = np.load('embeddings.npy')\n",
    "print(X.shape)\n",
    "\n",
    "#dividing into training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "#for performance metric\n",
    "#racism:0, sexism:1, none:2\n",
    "target_names = ['racism', 'sexism', 'none']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.79      0.65      0.71       179\n",
      "     sexism       0.86      0.33      0.48       329\n",
      "       none       0.79      0.95      0.86      1077\n",
      "\n",
      "avg / total       0.80      0.79      0.77      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.79      0.68      0.73       179\n",
      "     sexism       0.82      0.44      0.57       329\n",
      "       none       0.81      0.94      0.87      1077\n",
      "\n",
      "avg / total       0.81      0.81      0.79      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.81      0.70      0.75       179\n",
      "     sexism       0.82      0.52      0.64       329\n",
      "       none       0.83      0.94      0.88      1077\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=4, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.82      0.69      0.75       179\n",
      "     sexism       0.84      0.48      0.61       329\n",
      "       none       0.82      0.95      0.88      1077\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=8, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.66      0.73      0.69       179\n",
      "     sexism       0.49      0.50      0.50       329\n",
      "       none       0.80      0.78      0.79      1077\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.238586\ttest-merror:0.251104\n",
      "[1]\ttrain-merror:0.226033\ttest-merror:0.239117\n",
      "[2]\ttrain-merror:0.225191\ttest-merror:0.229022\n",
      "[3]\ttrain-merror:0.222175\ttest-merror:0.226498\n",
      "[4]\ttrain-merror:0.217196\ttest-merror:0.223975\n",
      "[5]\ttrain-merror:0.214321\ttest-merror:0.22082\n",
      "[6]\ttrain-merror:0.21397\ttest-merror:0.221451\n",
      "[7]\ttrain-merror:0.211025\ttest-merror:0.22082\n",
      "[8]\ttrain-merror:0.20864\ttest-merror:0.219558\n",
      "[9]\ttrain-merror:0.207308\ttest-merror:0.217035\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.79      0.60      0.68       179\n",
      "     sexism       0.89      0.28      0.43       329\n",
      "       none       0.77      0.97      0.86      1077\n",
      "\n",
      "avg / total       0.80      0.78      0.75      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 4\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.12841\ttest-merror:0.232177\n",
      "[1]\ttrain-merror:0.118031\ttest-merror:0.218297\n",
      "[2]\ttrain-merror:0.111509\ttest-merror:0.215773\n",
      "[3]\ttrain-merror:0.10674\ttest-merror:0.210095\n",
      "[4]\ttrain-merror:0.102321\ttest-merror:0.204416\n",
      "[5]\ttrain-merror:0.098815\ttest-merror:0.210726\n",
      "[6]\ttrain-merror:0.09622\ttest-merror:0.200631\n",
      "[7]\ttrain-merror:0.093906\ttest-merror:0.201893\n",
      "[8]\ttrain-merror:0.091241\ttest-merror:0.198738\n",
      "[9]\ttrain-merror:0.088225\ttest-merror:0.199369\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.78      0.66      0.71       179\n",
      "     sexism       0.86      0.38      0.53       329\n",
      "       none       0.80      0.95      0.87      1077\n",
      "\n",
      "avg / total       0.81      0.80      0.78      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 8\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.071323\ttest-merror:0.24164\n",
      "[1]\ttrain-merror:0.060453\ttest-merror:0.221451\n",
      "[2]\ttrain-merror:0.055053\ttest-merror:0.225237\n",
      "[3]\ttrain-merror:0.050915\ttest-merror:0.221451\n",
      "[4]\ttrain-merror:0.04825\ttest-merror:0.210726\n",
      "[5]\ttrain-merror:0.046427\ttest-merror:0.211987\n",
      "[6]\ttrain-merror:0.042429\ttest-merror:0.210095\n",
      "[7]\ttrain-merror:0.039975\ttest-merror:0.208202\n",
      "[8]\ttrain-merror:0.036819\ttest-merror:0.201262\n",
      "[9]\ttrain-merror:0.033593\ttest-merror:0.201893\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.75      0.65      0.70       179\n",
      "     sexism       0.83      0.41      0.55       329\n",
      "       none       0.80      0.94      0.87      1077\n",
      "\n",
      "avg / total       0.80      0.80      0.78      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 10\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.027772\ttest-merror:0.239748\n",
      "[1]\ttrain-merror:0.01592\ttest-merror:0.242271\n",
      "[2]\ttrain-merror:0.013115\ttest-merror:0.233438\n",
      "[3]\ttrain-merror:0.01094\ttest-merror:0.210726\n",
      "[4]\ttrain-merror:0.009398\ttest-merror:0.215142\n",
      "[5]\ttrain-merror:0.008696\ttest-merror:0.210726\n",
      "[6]\ttrain-merror:0.007925\ttest-merror:0.210095\n",
      "[7]\ttrain-merror:0.007434\ttest-merror:0.207571\n",
      "[8]\ttrain-merror:0.006312\ttest-merror:0.205047\n",
      "[9]\ttrain-merror:0.00547\ttest-merror:0.203155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.77      0.65      0.70       179\n",
      "     sexism       0.78      0.43      0.56       329\n",
      "       none       0.80      0.93      0.86      1077\n",
      "\n",
      "avg / total       0.79      0.80      0.78      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 16\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.238586\ttest-merror:0.251104\n",
      "[1]\ttrain-merror:0.219581\ttest-merror:0.226498\n",
      "[2]\ttrain-merror:0.210744\ttest-merror:0.223344\n",
      "[3]\ttrain-merror:0.204853\ttest-merror:0.21388\n",
      "[4]\ttrain-merror:0.198892\ttest-merror:0.210726\n",
      "[5]\ttrain-merror:0.193983\ttest-merror:0.207571\n",
      "[6]\ttrain-merror:0.188302\ttest-merror:0.204416\n",
      "[7]\ttrain-merror:0.184796\ttest-merror:0.203155\n",
      "[8]\ttrain-merror:0.180798\ttest-merror:0.201262\n",
      "[9]\ttrain-merror:0.177572\ttest-merror:0.197476\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.81      0.65      0.72       179\n",
      "     sexism       0.84      0.39      0.53       329\n",
      "       none       0.80      0.95      0.87      1077\n",
      "\n",
      "avg / total       0.81      0.80      0.78      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.4\n",
    "param['max_depth'] = 4\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.12841\ttest-merror:0.232177\n",
      "[1]\ttrain-merror:0.105828\ttest-merror:0.208833\n",
      "[2]\ttrain-merror:0.089838\ttest-merror:0.204416\n",
      "[3]\ttrain-merror:0.081001\ttest-merror:0.2\n",
      "[4]\ttrain-merror:0.072095\ttest-merror:0.198738\n",
      "[5]\ttrain-merror:0.06424\ttest-merror:0.200631\n",
      "[6]\ttrain-merror:0.055404\ttest-merror:0.196215\n",
      "[7]\ttrain-merror:0.048741\ttest-merror:0.197476\n",
      "[8]\ttrain-merror:0.044393\ttest-merror:0.196845\n",
      "[9]\ttrain-merror:0.036118\ttest-merror:0.188013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.82      0.67      0.74       179\n",
      "     sexism       0.83      0.44      0.57       329\n",
      "       none       0.81      0.95      0.87      1077\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.4\n",
    "param['max_depth'] = 8\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.071323\ttest-merror:0.24164\n",
      "[1]\ttrain-merror:0.051406\ttest-merror:0.214511\n",
      "[2]\ttrain-merror:0.039414\ttest-merror:0.203785\n",
      "[3]\ttrain-merror:0.027702\ttest-merror:0.198738\n",
      "[4]\ttrain-merror:0.021811\ttest-merror:0.194322\n",
      "[5]\ttrain-merror:0.01613\ttest-merror:0.195584\n",
      "[6]\ttrain-merror:0.011712\ttest-merror:0.194953\n",
      "[7]\ttrain-merror:0.009468\ttest-merror:0.196845\n",
      "[8]\ttrain-merror:0.006733\ttest-merror:0.197476\n",
      "[9]\ttrain-merror:0.005961\ttest-merror:0.194953\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.78      0.64      0.70       179\n",
      "     sexism       0.84      0.43      0.57       329\n",
      "       none       0.80      0.95      0.87      1077\n",
      "\n",
      "avg / total       0.81      0.81      0.79      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.4\n",
    "param['max_depth'] = 10\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.238586\ttest-merror:0.251104\n",
      "[1]\ttrain-merror:0.213409\ttest-merror:0.235331\n",
      "[2]\ttrain-merror:0.199102\ttest-merror:0.224606\n",
      "[3]\ttrain-merror:0.189564\ttest-merror:0.218927\n",
      "[4]\ttrain-merror:0.181359\ttest-merror:0.20694\n",
      "[5]\ttrain-merror:0.174486\ttest-merror:0.204416\n",
      "[6]\ttrain-merror:0.167543\ttest-merror:0.197476\n",
      "[7]\ttrain-merror:0.161722\ttest-merror:0.196845\n",
      "[8]\ttrain-merror:0.153166\ttest-merror:0.192429\n",
      "[9]\ttrain-merror:0.147135\ttest-merror:0.18612\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.80      0.69      0.74       179\n",
      "     sexism       0.82      0.46      0.59       329\n",
      "       none       0.82      0.94      0.87      1077\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.8\n",
    "param['max_depth'] = 4\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.12841\ttest-merror:0.232177\n",
      "[1]\ttrain-merror:0.098745\ttest-merror:0.22082\n",
      "[2]\ttrain-merror:0.075672\ttest-merror:0.20694\n",
      "[3]\ttrain-merror:0.056105\ttest-merror:0.200631\n",
      "[4]\ttrain-merror:0.04811\ttest-merror:0.196845\n",
      "[5]\ttrain-merror:0.038081\ttest-merror:0.203155\n",
      "[6]\ttrain-merror:0.027702\ttest-merror:0.198738\n",
      "[7]\ttrain-merror:0.019496\ttest-merror:0.192429\n",
      "[8]\ttrain-merror:0.012063\ttest-merror:0.194322\n",
      "[9]\ttrain-merror:0.009748\ttest-merror:0.191798\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.76      0.65      0.70       179\n",
      "     sexism       0.79      0.50      0.61       329\n",
      "       none       0.82      0.93      0.87      1077\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.8\n",
    "param['max_depth'] = 8\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.238586\ttest-merror:0.251104\n",
      "[1]\ttrain-merror:0.212848\ttest-merror:0.233438\n",
      "[2]\ttrain-merror:0.196718\ttest-merror:0.22082\n",
      "[3]\ttrain-merror:0.187461\ttest-merror:0.213249\n",
      "[4]\ttrain-merror:0.179185\ttest-merror:0.203785\n",
      "[5]\ttrain-merror:0.168455\ttest-merror:0.20694\n",
      "[6]\ttrain-merror:0.161442\ttest-merror:0.198738\n",
      "[7]\ttrain-merror:0.152816\ttest-merror:0.203785\n",
      "[8]\ttrain-merror:0.147065\ttest-merror:0.198738\n",
      "[9]\ttrain-merror:0.140613\ttest-merror:0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     racism       0.75      0.65      0.70       179\n",
      "     sexism       0.75      0.49      0.59       329\n",
      "       none       0.82      0.92      0.86      1077\n",
      "\n",
      "avg / total       0.79      0.80      0.79      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label = y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 1.0\n",
    "param['max_depth'] = 4\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "y_pred = bst.predict(xg_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
